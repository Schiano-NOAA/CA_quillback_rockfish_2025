### Sensitivity Analyses {#sec-assmt-sens}

<!-- Sensitivity to assumptions about model structure, i.e., model specification uncertainty.  -->

<!-- Sensitivity to data set choice (e.g., using emphasis factors to selectively remove data sources) and weighting schemes (e.g., MacAllister & Ianelli weighting versus Francis weighting vs. Dirichlet weighting for compositional data), which may also include a consideration of recent patterns in recruitment.  -->

The base model contains substantial uncertainty in both how data were processed, and structural assumptions made. We tested sensitivity to many of these assumptions. Sensitivities were conducted as a single exploration from the base model assumptions and/or data, and were not performed in a cumulative fashion unless specifically noted. In general, structural assumptions regarding population productivity led to the largest changes in model outputs [@fig-sens-overall]. All sensitivities with the exception of those related omitting growth data led to relatively similar estimates of growth parameters, indicating growth is consistently estimated in the model and we do not discuss it beyond sensitivities related to age data [@tbl-sens-biology--tbl-sens-selectivity]. We divide the sensitivities into five sections: biological parameters, population productivity, relative contributions of data sources, how data are prepared, how data are weighted, and selectivity. We also describe sensitivities done but not included in the document. 

#### Population Productivity

The base model makes a number of structural assumptions related to population productivity. These assumptions are known to be influential and drive how quickly a population will recover from fishing. In addition, new biological The following sensitivity models fall under population productivity:

-   Estimate $h$: Estimate steepness of the stock-recruit relationship.

-   Estimate $M$: Estimate natural mortality.

-   Estiamte $M$ and $h$: Estimate both natural mortality and steepness of the stock-recruit relationship.

-   Recdevs in 1990: Turn off estimation of recruitment deviations until 1990, which corresponds roughly to when deviations become more informative. 

-   No recdevs: Turn off estimation of recruitment deviations for all years, and assume recruitment follows the stock recruitment curve. 

#### Data Contributions



#### Data Choices

Compiling data for the assessment model required a number of choices and assumptions. The following sensitivity models fall under data choices:

-   Keep sparse comps: exclude all year-fleet combination of length and age composition data with input sample sizes less than five.

-   Remove ageing error: assume no ageing imprecision when reading age samples.

-   Commercial marginal age comps: use marginal age composition data for the commercial fleet instead of conditional age at length. For this model marginal age compositions were not weighted and sample size was based number of samples. 

-   Growth fleet marginal age comps: use marginal age composition data for the growth fleet instead of conditional age at length data.

-   Catch SE 0.1: increase the uncertainty in input catches from 0.05 to 0.1 for all years. Years before 1980 approximate the period with less extensive sampling, and where historical reconstructions are used to estimate catch. Adjusting catch standard error was done in lieu of manually changing catch streams to "low" and "high" scenarios.

-   Reduce large catches: catch estimates for the commercial fleet in 1991 and for the recreational fleet in 1984 and 1993 were particularly large compared to other years. For this model catch estimates in these years were assumed as averages from nearby years. 

-   Smooth catches: catch estimates for the commercial fleet in 1991 and for the recreational fleet in 1984 and 1993 were particularly large compared to other years. However, some years could also be abnormally low compared to other years. For this model a five year average smoother (two years on either side) was applied for all years.  

#### Data Weighting

The assessment model contains data from a variety of sources, some of which are expected to be more informative than others. Sampling units from these different data sources are not necessarily comparable (e.g., an observation from a survey index versus an observation of a fish length). Data weighting procedures are objective algorithms that can be used to assign weights to different data sources to optimize the fit of the model to the data. The following sensitivity models fall under data weighting:

-   McAllister-Ianelli data weighting: Use the algorithm suggested by @mcallister_bayesian_1997 instead of @francis_data_2011

-   Dirichlet-multinomial data weighting: Apply the algorithm suggested by @thorson_model-based_2017 instead of @francis_data_2011

-   Extra SD: Estimate an extra standard deviation for all survey indices, which include the recreational, \gls{s-ccfrp}, and \gls{rov} indices. This allows each index to be down-weighted to allow for better fitting of other data sources.

**FROG: Consider combining with leaveOut data choices**

#### Selectivity 

#### Sensitivities Not Included in Document

Using \gls{mrfss} length samples instead of those from the Deb Wilson-Vandenberg data, including length and conditional age at length compositions in years with sparse sample size (<5 for lengths and <30 for ages), excluding the most recent year of recreational length composition data, and estimating a fourth parameter of the double-normal selectivity curve for all fleets all had minimal impacts on model outputs.
